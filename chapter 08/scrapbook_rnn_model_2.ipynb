{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_sequences(n=128, variable_len=False, seed=13):\n",
    "    basic_corners = np.array([[-1, -1], [-1, 1], [1, 1], [1, -1]])\n",
    "    np.random.seed(seed)\n",
    "    bases = np.random.randint(4, size=n)\n",
    "    if variable_len:\n",
    "        lengths = np.random.randint(3, size=n) + 2\n",
    "    else:\n",
    "        lengths = [4] * n\n",
    "    directions = np.random.randint(2, size=n)\n",
    "    points = [basic_corners[[(b + i) % 4 for i in range(4)]][slice(None, None, d*2-1)][:l] + np.random.randn(l, 2) * 0.1 for b, d, l in zip(bases, directions, lengths)]\n",
    "    return points, directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, directions = generate_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(np.array(points)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(np.array(directions)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X, y)\n",
    "data_loader = DataLoader(train_data, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 2 dimensional hidden state from scratch\n",
    "hidden_state = torch.zeros((2,))\n",
    "hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = nn.RNNCell(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih',\n",
       "              tensor([[-0.5690,  0.6881, -0.3313,  0.6337, -0.5018, -0.2007, -0.0716,  0.0497,\n",
       "                        0.1755, -0.4532],\n",
       "                      [-0.2095,  0.3850,  0.3785,  0.6666,  0.2061, -0.4660, -0.6054,  0.1116,\n",
       "                       -0.5396, -0.0775]])),\n",
       "             ('weight_hh',\n",
       "              tensor([[ 0.3329, -0.3152],\n",
       "                      [ 0.0772,  0.1730]])),\n",
       "             ('bias_ih', tensor([0.4247, 0.5085])),\n",
       "             ('bias_hh', tensor([ 0.1556, -0.3878]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_cell.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_layer = nn.RNN(input_size = 2, hidden_size = 2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0',\n",
       "              tensor([[-0.5745, -0.1672],\n",
       "                      [-0.4453,  0.5029]])),\n",
       "             ('weight_hh_l0',\n",
       "              tensor([[0.2316, 0.3645],\n",
       "                      [0.2534, 0.1772]])),\n",
       "             ('bias_ih_l0', tensor([-0.1964, -0.5988])),\n",
       "             ('bias_hh_l0', tensor([-0.6760, -0.2726]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, final_hidden = rnn_layer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=2, output_size=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.rnn = nn.GRU(self.input_size, self.hidden_size, batch_first = True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out, context = self.rnn(X)\n",
    "        return self.linear(out[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1566],\n",
       "        [0.0027],\n",
       "        [0.1780]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7021885777628699\n",
      "Loss: 0.6963924058648043\n",
      "Loss: 0.6853939433430516\n",
      "Loss: 0.67826511000478\n",
      "Loss: 0.6581848416217538\n",
      "Loss: 0.6146305667799573\n",
      "Loss: 0.5068138650683469\n",
      "Loss: 0.36363881133323495\n",
      "Loss: 0.22799104400152384\n",
      "Loss: 0.14133570776429288\n",
      "Loss: 0.09009279293376346\n",
      "Loss: 0.06138141518242137\n",
      "Loss: 0.044265887418458626\n",
      "Loss: 0.034114215068172575\n",
      "Loss: 0.02763068426920231\n",
      "Loss: 0.02304534566437089\n",
      "Loss: 0.019621746961114017\n",
      "Loss: 0.017116401431172393\n",
      "Loss: 0.015142826601689639\n",
      "Loss: 0.013518066990167596\n",
      "Loss: 0.012230572539793198\n",
      "Loss: 0.011177343836184158\n",
      "Loss: 0.010265471500366233\n",
      "Loss: 0.00945228835307928\n",
      "Loss: 0.008807919237242882\n",
      "Loss: 0.00823000492528081\n",
      "Loss: 0.007709241298915342\n",
      "Loss: 0.007245355745950757\n",
      "Loss: 0.006865604683150386\n",
      "Loss: 0.006457501128965685\n",
      "Loss: 0.006137296459962463\n",
      "Loss: 0.005836532321260419\n",
      "Loss: 0.005592009355855542\n",
      "Loss: 0.005336104632290297\n",
      "Loss: 0.005117060210512474\n",
      "Loss: 0.004898107697277568\n",
      "Loss: 0.004717039290902226\n",
      "Loss: 0.00453199821979154\n",
      "Loss: 0.004351662531451777\n",
      "Loss: 0.0042045558586196845\n",
      "Loss: 0.004037998800794053\n",
      "Loss: 0.003938944569009162\n",
      "Loss: 0.0037861375062358243\n",
      "Loss: 0.0036666905101345377\n",
      "Loss: 0.003557569214662667\n",
      "Loss: 0.0034594581283758892\n",
      "Loss: 0.0033486626804048237\n",
      "Loss: 0.0032603055547359722\n",
      "Loss: 0.0031905636749078713\n",
      "Loss: 0.003087981070695055\n",
      "Loss: 0.003009343595612188\n",
      "Loss: 0.002941650966572207\n",
      "Loss: 0.0028705250872515663\n",
      "Loss: 0.002798684371830246\n",
      "Loss: 0.002720536886129615\n",
      "Loss: 0.002664674327947026\n",
      "Loss: 0.002592955927126283\n",
      "Loss: 0.002532956807679215\n",
      "Loss: 0.0024840084289005676\n",
      "Loss: 0.002429477997708979\n",
      "Loss: 0.0023978614102139377\n",
      "Loss: 0.002331747272766607\n",
      "Loss: 0.0022961561416470727\n",
      "Loss: 0.0022487919615191776\n",
      "Loss: 0.002210587604231266\n",
      "Loss: 0.002159937352570164\n",
      "Loss: 0.0021178469164730156\n",
      "Loss: 0.002084122063743687\n",
      "Loss: 0.0020426690638022022\n",
      "Loss: 0.002006355004363455\n",
      "Loss: 0.001974761050172843\n",
      "Loss: 0.001939361652381025\n",
      "Loss: 0.0019069542231168165\n",
      "Loss: 0.001872896395493732\n",
      "Loss: 0.0018427255400997955\n",
      "Loss: 0.0018219290988866327\n",
      "Loss: 0.0017869607274702123\n",
      "Loss: 0.0017600739198780164\n",
      "Loss: 0.001734647572278803\n",
      "Loss: 0.0017042222695403495\n",
      "Loss: 0.0016862146331668767\n",
      "Loss: 0.0016534915424038677\n",
      "Loss: 0.0016284735756926239\n",
      "Loss: 0.0016100053177323453\n",
      "Loss: 0.0015941676751407253\n",
      "Loss: 0.0015632858930350563\n",
      "Loss: 0.0015410304253617691\n",
      "Loss: 0.0015236036269925535\n",
      "Loss: 0.0015031550510050079\n",
      "Loss: 0.0014883386347507841\n",
      "Loss: 0.0014663729573015211\n",
      "Loss: 0.0014674984795842753\n",
      "Loss: 0.0014254983871915313\n",
      "Loss: 0.0014061910184208564\n",
      "Loss: 0.001395419126289875\n",
      "Loss: 0.0013784633781544345\n",
      "Loss: 0.0013627394313685769\n",
      "Loss: 0.0013460815142363656\n",
      "Loss: 0.0013302560519362085\n",
      "Loss: 0.0013124435317031172\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for X, y in data_loader:\n",
    "        model.train()\n",
    "        y_hat = model(X)\n",
    "        loss = loss_fn(y_hat, y.view(-1,1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    history.append(np.array(batch_loss).mean())\n",
    "    print(f\"Loss: {history[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train).clip(0,1).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
